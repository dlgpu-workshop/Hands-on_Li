{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ef926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import imageio.v2 as imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "def normalize_images():\n",
    "    PATH = './Sample800_1'\n",
    "    OUT_PATH = './Sample800_norm1'\n",
    "    FILE_TYPE = '.tif'\n",
    "\n",
    "    if not os.path.exists(OUT_PATH):\n",
    "        os.makedirs(OUT_PATH)\n",
    "\n",
    "\n",
    "    def apply_sobel(image,RGB=False):\n",
    "        #Apply sobel filter to refine edges\n",
    "        if(RGB == False):\n",
    "            gray = image\n",
    "        else:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "        abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "        abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "        grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "        return grad\n",
    "\n",
    "    def normalize_image(img_path,out_path):\n",
    "        image = imageio.imread(img_path)\n",
    "        array = np.array(image)\n",
    "        normalized = (array.astype(np.float32) - array.min()) / (array.max() - array.min())\n",
    "\n",
    "        # scale normalized image to 0-65535 range\n",
    "        scaled = np.uint16(normalized * 65535)\n",
    "\n",
    "        # convert back to PIL for saving\n",
    "        image = Image.fromarray(scaled)\n",
    "        image.save(out_path, \"TIFF\")\n",
    "        return image\n",
    "\n",
    "\n",
    "    file_list = os.listdir(PATH)\n",
    "\n",
    "    for filename in tqdm(file_list):\n",
    "        if filename.endswith(FILE_TYPE):\n",
    "            # Normalise to range 0..1\n",
    "            norm = normalize_image(PATH+'/'+filename,OUT_PATH+'/'+filename)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    normalize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74fabfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.59it/s]\n"
     ]
    }
   ],
   "source": [
    "def normalize_images(): \n",
    "    PATH = './Sample800_1'\n",
    "    OUT_PATH = './Sample800_norm1'\n",
    "    FILE_TYPE = '.tif'\n",
    "\n",
    "    if not os.path.exists(OUT_PATH):\n",
    "        os.makedirs(OUT_PATH)\n",
    "\n",
    "\n",
    "    def apply_sobel(image,RGB=False):\n",
    "        #Apply sobel filter to refine edges\n",
    "        if(RGB == False):\n",
    "            gray = image\n",
    "        else:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "        abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "        abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "        grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "        return grad\n",
    "\n",
    "    def normalize_image(img_path,out_path):\n",
    "\n",
    "        image = imageio.imread(img_path)      \n",
    "        array = np.array(image)\n",
    "        normalized = (array.astype(np.uint16) - array.min()) * 255.0 / (array.max() - array.min())\n",
    "\n",
    "        image = np.array(Image.fromarray(normalized.astype(np.uint32)))\n",
    "\n",
    "        #image = apply_sobel(image)\n",
    "\n",
    "        # convert back to PIL for saving\n",
    "        image = Image.fromarray(image)\n",
    "        image.save(out_path, \"TIFF\")\n",
    "        return image\n",
    "\n",
    "\n",
    "    file_list = os.listdir(PATH)\n",
    "\n",
    "    for filename in tqdm(file_list):\n",
    "        if filename.endswith(FILE_TYPE):\n",
    "            # Normalise to range 0..255\n",
    "            norm = normalize_image(PATH+'/'+filename,OUT_PATH+'/'+filename)\n",
    "\n",
    "            #print(converted_image.save(OUT_PATH+filename))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    normalize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1346b79b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_model\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NUM_EPOCHS, SAVE_MODEL_EPOCH, NUM_CLASSES, CLASSES, INFER_FALSE_LABELS,DETECTION_THRESHOLD\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import glob as glob\n",
    "from model import create_model\n",
    "from config import NUM_EPOCHS, SAVE_MODEL_EPOCH, NUM_CLASSES, CLASSES, INFER_FALSE_LABELS,DETECTION_THRESHOLD\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "NOTE: Relative paths are used in this file. These paths are relative to the root directory. If you intend on running\n",
    "        This code from this file specifically, you must change them to go back a directory \n",
    "        (ie. ../outputs/model rather than ./outputs/model)\n",
    "         '''\n",
    "\n",
    "def inference():\n",
    "    #compute the latest saved model based on the number of epochs and saving interval\n",
    "    #np.floor((NUM_EPOCHS/SAVE_MODEL_EPOCH)*SAVE_MODEL_EPOCH)\n",
    "    # set the computation device\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # load the model and the trained weights\n",
    "    model = create_model(num_classes=NUM_CLASSES).to(device)\n",
    "    model.load_state_dict(torch.load(\n",
    "        './outputs/model'+str(NUM_EPOCHS)+'.pth', map_location=device\n",
    "    ))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa938e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
